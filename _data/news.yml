- date: 2024-09-03
  text: Presentation at Interspeech 2024 about [UNIVERSE++](https://arxiv.org/abs/2406.12194), a diffusion-based universal speech enhancement model with high content preservation (work done at LY Corp.).
- date: 2024-07-08
  text: I have joined [Google Deepmind](https://deepmind.google/).
- date: 2020-11-25
  text: "I gave a high level presentation of our work on optimization for blind source separation during LINE DEV DAY 2020. Watch the [video](https://www.youtube.com/watch?v=4dqwJ_rpkPc)."
- date: 2019-08-25
  text: "Autumn will be busy. We will present our paper [Indpendent Vector Analysis with more Microphones than Sources](https://arxiv.org/abs/1905.07880) at WASPAA in October. The [code](https://github.com/onolab-tmu/overiva/) is already available. In addition, Daiki Horiike will present \"Blink-former: Light-aided beamforming for multiple targets enhancement\" at MMSP, and Kouei Yamaoka will present \"Sub-Sample  Time  Delay Estimation via Auxiliary-Function-Based Iterative Updates\" at WASPAA too."
- date: 2019-03-15
  text: "We presented our work on using [blinkies](/otohikari) for source separation and acoustic event detection at the [SIP symposium](https://www.ieice.org/ken/program/index.php?tgs_regid=e31ba246e18f5dad1ef9a09d03421118ad3f4f51935212302bab39e5dd5c4078&tgid=IEICE-SP&lang=) in Nagasaki."
- date: 2019-02-03
  text: "Our paper [*Multi-modal blind source separation with microphones and blinkies*](https://arxiv.org/pdf/1904.02334.pdf) has been accepted at [ICASSP 2019](http://icassp2019.com/)."
- date: 2018-11-16
  text: "We presented our paper [*Blinkies: Sound-to-light conversion sensors and their application to speech enhancement and sound source localization*](http://www.apsipa.org/proceedings/2018/pdfs/0001899.pdf) at [APSIPA 2018](https://www.apsipa2018.org/) in Honolulu."
